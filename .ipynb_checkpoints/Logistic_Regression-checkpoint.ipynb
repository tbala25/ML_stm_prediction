{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## IMPORTS ####################\n",
    "from localLibrary_AWSConnector import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime \n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS\n",
    "\n",
    "#Returns dictionary of dataframes\n",
    "def get_data():\n",
    "    data_list = []\n",
    "    data_dict = {}\n",
    "    \n",
    "    file_dir = os.getcwd() + '\\\\data\\\\'\n",
    "    items = os.listdir(file_dir)\n",
    "    \n",
    "    for i in items:\n",
    "        if i == 'SG_STM_purchase_date.csv':\n",
    "            pass\n",
    "        else:\n",
    "            file = i.replace('.csv', '')\n",
    "            data_list.append(file)\n",
    "\n",
    "            # Save STM files as DataFrames\n",
    "            data_dict[file] = pd.read_csv(file_dir + i, index_col=0)\n",
    "\n",
    "    print(data_list)\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "#Convert time helper\n",
    "def _convert_time_to_int(time):\n",
    "    #print(time)\n",
    "    if time != time:\n",
    "        return 0\n",
    "    elif time == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(''.join(c for c in time if c.isdigit()))\n",
    "\n",
    "#convert date columns to int  for given df   \n",
    "def convert_time_int(df):\n",
    "    \n",
    "    df['EarliestCRM_int'] = [_convert_time_to_int(x) for x in df['EarliestCRM']]\n",
    "    df['LatestCRM_int'] = [_convert_time_to_int(x) for x in df['LatestCRM']]\n",
    "\n",
    "    df['LatestSeatGeek_int'] = [_convert_time_to_int(x) for x in df['LatestSeatGeekDate']]\n",
    "    df['EarliestSeatGeek_int'] = [_convert_time_to_int(x) for x in df['EarliestSeatGeekDate']]\n",
    "\n",
    "    df['EarliestMarketo_int'] = [_convert_time_to_int(x) for x in df['EarliestMarketoDate']]\n",
    "    df['LatestMarketo_int'] = [_convert_time_to_int(x) for x in df['LatestMarketoDate']]\n",
    "\n",
    "    df['EarliestFanatics_int'] = [_convert_time_to_int(x) for x in df['EarliestFanaticsDate']]\n",
    "    df['LatestFanatics_int'] = [_convert_time_to_int(x) for x in df['LatestFanaticsDate']]\n",
    "\n",
    "    df['EarliestYinzcam_int'] = [_convert_time_to_int(x) for x in df['EarliestYinzcamDate']]\n",
    "    df['LatestYinzcam_int'] = [_convert_time_to_int(x) for x in df['LatestYinzcamDate']]\n",
    "    \n",
    "    df['Purchase Date'] = [_convert_time_to_int(x) for x in df['Purchase Date']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Creates date difference column (latest - earliest)\n",
    "def calculate_time_diff(df):\n",
    "    \n",
    "    df['CRM_diff'] = df['LatestCRM_int'] - df['EarliestCRM_int']\n",
    "    df['SeatGeek_diff'] = df['LatestSeatGeek_int'] - df['EarliestSeatGeek_int']\n",
    "    df['Marketo_diff'] = df['LatestMarketo_int'] - df['EarliestMarketo_int']\n",
    "    df['Fanatics_diff'] = df['LatestFanatics_int'] - df['EarliestFanatics_int']\n",
    "    df['Yinzcam_diff'] = df['LatestYinzcam_int'] - df['EarliestYinzcam_int']\n",
    "    \n",
    "    df['CRM_to_purchase'] = df['Purchase Date'] - df['LatestCRM_int']\n",
    "    df['SeatGeek_to_purchase'] = df['Purchase Date'] - df['LatestSeatGeek_int']\n",
    "    df['Marketo_to_purchase'] = df['Purchase Date'] - df['LatestMarketo_int']\n",
    "    df['Fanatics_to_purchase'] = df['Purchase Date'] - df['LatestFanatics_int']\n",
    "    df['Yinzcam_to_purchase'] = df['Purchase Date'] - df['LatestYinzcam_int']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRM_lost', 'CRM_nonSTM', 'CRM_STM', 'FTS_lost', 'FTS_nonSTM', 'FTS_STM', 'MK_lost', 'MK_nonSTM', 'MK_STM', 'SG_lost', 'SG_nonSTM', 'SG_STM', 'YZ_lost', 'YZ_nonSTM', 'YZ_STM']\n"
     ]
    }
   ],
   "source": [
    "all_data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "archived_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in all_data.keys():\n",
    "    #SEATGEEK PIVOT\n",
    "    if 'SG' in key:\n",
    "        pivoted = pd.pivot_table(all_data[key], \n",
    "                         values=['TotalSeatGeekTransactions','TotalTicketVolume','TotalScannedTicketVolume','TotalTicketDollarValue'], \n",
    "                         index=['SSB_CRMSYSTEM_CONTACT_ID'],\n",
    "                         columns=['cjsgActivityType', 'cjsgSecondaryTicketType'], \n",
    "                         aggfunc=(np.sum), \n",
    "                         fill_value=0)\n",
    "        #pivoted.columns = [' '.join(col).strip() for col in pivoted.columns.values]\n",
    "        pivoted = pd.DataFrame(pivoted.to_records())\n",
    "\n",
    "        pivoted_agg = pd.DataFrame()\n",
    "        pivoted_agg['SSB_CRMSYSTEM_CONTACT_ID'] = pivoted['SSB_CRMSYSTEM_CONTACT_ID']\n",
    "        pivoted_agg['total_scanned'] = pivoted[\"('TotalScannedTicketVolume', 'Purchase', 'Primary')\"] + pivoted[\"('TotalScannedTicketVolume', 'Purchase', 'Resale')\"] + pivoted[\"('TotalScannedTicketVolume', 'Purchase', 'Transfer')\"]\n",
    "\n",
    "        pivoted_agg['primary_purchase_transactions'] = pivoted[\"('TotalSeatGeekTransactions', 'Purchase', 'Primary')\"]\n",
    "        pivoted_agg['secondary_purchase_transactions'] = pivoted[\"('TotalSeatGeekTransactions', 'Purchase', 'Resale')\"] + pivoted[\"('TotalSeatGeekTransactions', 'Purchase', 'Transfer')\"]\n",
    "        pivoted_agg['secondary_sell_transactions'] = pivoted[\"('TotalSeatGeekTransactions', 'Sell', 'Resale')\"] + pivoted[\"('TotalSeatGeekTransactions', 'Sell', 'Transfer')\"]\n",
    "\n",
    "        pivoted_agg['primary_purchase_dollars'] = pivoted[\"('TotalTicketDollarValue', 'Purchase', 'Primary')\"]\n",
    "        pivoted_agg['secondary_purchase_dollars'] = pivoted[\"('TotalTicketDollarValue', 'Purchase', 'Resale')\"] + pivoted[\"('TotalTicketDollarValue', 'Purchase', 'Transfer')\"]\n",
    "        pivoted_agg['secondary_sell_dollars'] = pivoted[\"('TotalTicketDollarValue', 'Sell', 'Resale')\"] + pivoted[\"('TotalTicketDollarValue', 'Sell', 'Transfer')\"]\n",
    "\n",
    "        pivoted_agg['primary_purchase_tickets'] = pivoted[\"('TotalTicketVolume', 'Purchase', 'Primary')\"]\n",
    "        pivoted_agg['secondary_purchase_tickets'] = pivoted[\"('TotalTicketVolume', 'Purchase', 'Resale')\"] + pivoted[\"('TotalTicketVolume', 'Purchase', 'Transfer')\"]\n",
    "        pivoted_agg['secondary_sell_tickets'] = pivoted[\"('TotalTicketVolume', 'Sell', 'Resale')\"] + pivoted[\"('TotalTicketVolume', 'Sell', 'Transfer')\"]\n",
    "\n",
    "        min_dates = all_data[key]['EarliestSeatGeekDate'].groupby(['SSB_CRMSYSTEM_CONTACT_ID']).min()\n",
    "        max_dates = all_data[key]['LatestSeatGeekDate'].groupby(['SSB_CRMSYSTEM_CONTACT_ID']).max()\n",
    "        pivoted_agg = pivoted_agg.merge(min_dates, on = 'SSB_CRMSYSTEM_CONTACT_ID')\n",
    "        pivoted_agg = pivoted_agg.merge(max_dates, on = 'SSB_CRMSYSTEM_CONTACT_ID')\n",
    "        \n",
    "        all_data[key] = pivoted_agg\n",
    "        \n",
    "    #MARKETO PIVOT\n",
    "    if 'MK' in key:\n",
    "        pivoted = pd.pivot_table(all_data[key], \n",
    "                         values=['TotalMarketoVolume'], \n",
    "                         index=['SSB_CRMSYSTEM_CONTACT_ID'],\n",
    "                         columns=['cjmktActivityType'], \n",
    "                         aggfunc=(np.sum), \n",
    "                         fill_value=0)\n",
    "\n",
    "        pivoted.columns = pivoted.columns.droplevel(0)\n",
    "        min_dates = all_data[key]['EarliestMarketoDate'].groupby(['SSB_CRMSYSTEM_CONTACT_ID']).min()\n",
    "        max_dates = all_data[key]['LatestMarketoDate'].groupby(['SSB_CRMSYSTEM_CONTACT_ID']).max()\n",
    "        pivoted = pivoted.merge(min_dates, on = 'SSB_CRMSYSTEM_CONTACT_ID')\n",
    "        pivoted = pivoted.merge(max_dates, on = 'SSB_CRMSYSTEM_CONTACT_ID')\n",
    "        \n",
    "        all_data[key] = pivoted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_purchase = pd.read_csv('./data/SG_STM_purchase_date.csv', header = None)\n",
    "stm_purchase.columns = ['SSB_CRMSYSTEM_CONTACT_ID', 'Purchase Date']\n",
    "all_data['SG_STM'] = stm_purchase.merge(all_data['SG_STM'], how = 'left', on = 'SSB_CRMSYSTEM_CONTACT_ID').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['SG_nonSTM']['Purchase Date'] = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "all_data['SG_lost']['Purchase Date'] = datetime.datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE all DF for STM  \n",
    "STM = None\n",
    "nonSTM = None\n",
    "lost = None\n",
    "for key in all_data.keys():\n",
    "    df = all_data[key]\n",
    "    if('STM' in key and 'non' not in key): \n",
    "        if STM is None:\n",
    "            STM = df\n",
    "        else:\n",
    "            STM = STM.merge(df, how = 'outer', on = 'SSB_CRMSYSTEM_CONTACT_ID')\n",
    "\n",
    "    elif('non' in key): \n",
    "        if nonSTM is None:\n",
    "            nonSTM = df\n",
    "        else:\n",
    "            nonSTM = nonSTM.merge(df, how = 'outer', on = 'SSB_CRMSYSTEM_CONTACT_ID')\n",
    "    elif('lost' in key): \n",
    "        if lost is None:\n",
    "            lost = df\n",
    "        else:\n",
    "            lost = lost.merge(df, how = 'outer', on = 'SSB_CRMSYSTEM_CONTACT_ID')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT DATE COLUMNS TO INT\n",
    "\n",
    "STM = convert_time_int(STM)\n",
    "nonSTM = convert_time_int(nonSTM)\n",
    "lost = convert_time_int(lost)\n",
    "\n",
    "#filter records from lost where marketo + crm + sg are over a year old\n",
    "# lost[lost['']]\n",
    "\n",
    "# #CALCULATE DATE DIFFERENCE\n",
    "# #QUANTIFY LENGTH OF ENGAGEMENT\n",
    "\n",
    "# STM = calculate_time_diff(STM)\n",
    "# nonSTM = calculate_time_diff(nonSTM)\n",
    "# lost = calculate_time_diff(lost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarliestFanaticsDate\n",
      "LatestFanaticsDate\n",
      "EarliestMarketoDate\n",
      "LatestMarketoDate\n",
      "Purchase Date\n",
      "EarliestSeatGeekDate\n",
      "LatestSeatGeekDate\n",
      "EarliestYinzcamDate\n",
      "LatestYinzcamDate\n",
      "EarliestCRM_int\n",
      "LatestCRM_int\n",
      "LatestSeatGeek_int\n",
      "EarliestSeatGeek_int\n",
      "EarliestMarketo_int\n",
      "LatestMarketo_int\n",
      "EarliestFanatics_int\n",
      "LatestFanatics_int\n",
      "EarliestYinzcam_int\n",
      "LatestYinzcam_int\n"
     ]
    }
   ],
   "source": [
    "#DROP DATE COLUMNS\n",
    "for col in STM.columns:\n",
    "    if 'Date' in col:\n",
    "        print(col)\n",
    "        STM.drop([col], axis=1, inplace = True)\n",
    "        nonSTM.drop([col], axis=1, inplace = True)\n",
    "        lost.drop([col], axis=1, inplace = True)\n",
    "    elif '_int' in col:\n",
    "        print(col)\n",
    "        STM.drop([col], axis=1, inplace = True)\n",
    "        nonSTM.drop([col], axis=1, inplace = True)\n",
    "        lost.drop([col], axis=1, inplace = True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "STM.drop(['EarliestCRM', 'LatestCRM'], axis=1, inplace = True)\n",
    "nonSTM.drop(['EarliestCRM', 'LatestCRM'], axis=1, inplace = True)\n",
    "lost.drop(['EarliestCRM', 'LatestCRM'], axis=1, inplace = True) \n",
    "\n",
    "# STM.drop(['Purchase Date'], axis=1, inplace = True)\n",
    "# nonSTM.drop(['Purchase Date'], axis=1, inplace = True)\n",
    "# lost.drop(['Purchase Date'], axis=1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STM Length: 3839\n",
      "nonSTM Length: 1468421\n",
      "lost Length: 85561\n"
     ]
    }
   ],
   "source": [
    "print(f\"STM Length: {len(STM)}\")\n",
    "print(f\"nonSTM Length: {len(nonSTM)}\")\n",
    "print(f\"lost Length: {len(lost)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get percent null in each column across the merged datasets\n",
    "stm_null = pd.DataFrame(STM.isna().sum()/len(STM), columns = ['STM_Pct_Null'])\n",
    "nonstm_null = pd.DataFrame(nonSTM.isna().sum()/len(nonSTM), columns = ['nonSTM_Pct_Null'])\n",
    "lost_null = pd.DataFrame(lost.isna().sum()/len(lost), columns = ['lost_Pct_Null'])\n",
    "\n",
    "all_null = stm_null.merge(nonstm_null.merge(lost_null, left_index=True, right_index=True), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_null.sort_values(by = 'STM_Pct_Null', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STM = STM.fillna(0)\n",
    "nonSTM = nonSTM.fillna(0)\n",
    "lost = lost.fillna(0)\n",
    "\n",
    "for c in lost.columns.values:\n",
    "    if 'zz' in c:\n",
    "        print(c)\n",
    "        lost.drop([c], axis = 0, inplace = True)\n",
    "    if 'Group Form' in c:\n",
    "        lost.drop([c], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STACK STM NONSTM, LOST\n",
    "\n",
    "STM['target'] = 'STM'\n",
    "lost['target'] = 'Rejecter'\n",
    "nonSTM['target'] = 'nonSTM'\n",
    "\n",
    "full_data = pd.concat([STM, lost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rejecter    0.957058\n",
       "STM         0.042942\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['target'].value_counts()/ len(full_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secondary_sell_transactions      secondary_sell_tickets             0.979761\n",
       "secondary_sell_tickets           secondary_sell_transactions        0.979761\n",
       "TotalFanaticsTransactions        TotalFanaticsProductQty            0.978813\n",
       "TotalFanaticsProductQty          TotalFanaticsTransactions          0.978813\n",
       "total_scanned                    primary_purchase_tickets           0.964105\n",
       "primary_purchase_tickets         total_scanned                      0.964105\n",
       "secondary_purchase_transactions  secondary_purchase_tickets         0.940057\n",
       "secondary_purchase_tickets       secondary_purchase_transactions    0.940057\n",
       "TotalFanaticsDollarValue         TotalFanaticsTransactions          0.890810\n",
       "TotalFanaticsTransactions        TotalFanaticsDollarValue           0.890810\n",
       "TotalFanaticsProductQty          TotalFanaticsDollarValue           0.869069\n",
       "TotalFanaticsDollarValue         TotalFanaticsProductQty            0.869069\n",
       "secondary_sell_dollars           secondary_sell_transactions        0.827136\n",
       "secondary_sell_transactions      secondary_sell_dollars             0.827136\n",
       "secondary_sell_dollars           secondary_sell_tickets             0.821756\n",
       "secondary_sell_tickets           secondary_sell_dollars             0.821756\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = full_data.drop(['SSB_CRMSYSTEM_CONTACT_ID', 'target'], axis = 1).corr().abs()\n",
    "\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending = False)\n",
    "so[so > .8 ][so < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns removed:\n",
      "['CRM Sync' 'Email Bounced' 'Email Sign-Up' 'Fanatics'\n",
      " 'Fill Out Facebook Lead Ads Form' 'Form Submission' 'Lead-Gen'\n",
      " 'List Import' 'Received Forward to Friend Email'\n",
      " 'Sent Forward to Friend Email' 'Suite & Premium Inquiry Form'\n",
      " 'TotalFanaticsProductQty' 'TotalFanaticsTransactions' 'Unsubscribe Email'\n",
      " 'secondary_purchase_transactions']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def variance_threshold_selector(data, threshold=0.5):\n",
    "    # https://stackoverflow.com/a/39813304/1956309\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "# min_variance = .9 * (1 - .9)  # You can play here with different values.\n",
    "min_variance = 3\n",
    "df = full_data[full_data['target'] == 'STM'].drop(['SSB_CRMSYSTEM_CONTACT_ID', 'target'], axis = 1)\n",
    "low_variance = variance_threshold_selector(df\n",
    "                                           ,min_variance) \n",
    "print('columns removed:')\n",
    "dropped_cols = (df.columns ^ low_variance.columns).values\n",
    "print(dropped_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped based on minimam variance\n",
    "dropped = full_data.drop(dropped_cols, axis = 1)\n",
    "#dropped based on multi collinearity\n",
    "dropped.drop(['secondary_sell_transactions',\n",
    "              'primary_purchase_tickets' ], axis = 1, inplace = True)\n",
    "#iterative dropping based on p values\n",
    "dropped.drop(['secondary_sell_dollars', 'secondary_purchase_dollars', 'secondary_sell_tickets', 'primary_purchase_dollars',\n",
    "             'secondary_purchase_tickets', 'TotalFanaticsDollarValue', \n",
    "              'total_scanned', 'Click Link', 'TotalYinzcamVolume', 'Visit Webpage'],\n",
    "             axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as sk\n",
    "\n",
    "sampled = dropped.sample(frac=1)\n",
    "\n",
    "X = sampled.drop(['SSB_CRMSYSTEM_CONTACT_ID','target'], axis = 1)\n",
    "y = sampled['target']\n",
    "label_encoder = sk.LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X.astype(float)).fit_regularized()\n",
    "#result=logit_model.fit()\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(X_train, y_train, X_test, y_test):\n",
    "    log = LogisticRegression(penalty='l1', solver='liblinear').fit(X_train, y_train)\n",
    "    #log = LogisticRegression(solver='liblinear', random_state=0).fit(X_train, y_train)\n",
    "    roc_score = roc_auc_score(y_test, log.predict_proba(X_test)[:,1])\n",
    "    recall = recall_score(y_test, log.predict(X_test))\n",
    "    precision = precision_score(y_test, log.predict(X_test))\n",
    "    print(roc_score)\n",
    "    print(recall)\n",
    "    print(precision)\n",
    "    return (roc_score, recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5) # Define the split - into 5 folds \n",
    "roc = 0\n",
    "prec = 0\n",
    "rec = 0\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    ro,re,p = train_and_predict(X_train, y_train, X_test, y_test)\n",
    "    roc += ro\n",
    "    prec += p\n",
    "    rec += re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "X, y = undersample.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1315 1318 1319 ... 6907 6908 6909] TEST: [   0    1    2 ... 1444 1445 1446]\n",
      "0.8820801246541747\n",
      "0.8176555716353111\n",
      "0.9608843537414966\n",
      "TRAIN: [   0    1    2 ... 6907 6908 6909] TEST: [1315 1318 1319 ... 2791 2795 2797]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\balat\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8998106730948456\n",
      "0.8350217076700435\n",
      "0.9730185497470489\n",
      "TRAIN: [   0    1    2 ... 6907 6908 6909] TEST: [2736 2738 2741 ... 4151 4152 4153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\balat\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997111926966729\n",
      "0.8364688856729378\n",
      "0.9697986577181208\n",
      "TRAIN: [   0    1    2 ... 6907 6908 6909] TEST: [4130 4132 4135 ... 5554 5557 5559]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\balat\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8839660635711158\n",
      "0.8191027496382055\n",
      "0.9843478260869565\n",
      "TRAIN: [   0    1    2 ... 5554 5557 5559] TEST: [5500 5504 5505 ... 6907 6908 6909]\n",
      "0.8852833934753425\n",
      "0.8234442836468886\n",
      "0.969335604770017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\balat\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_use, X_holdout, y_use, y_holdout = train_test_split(X, y, stratify=y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5) # Define the split - into 5 folds \n",
    "roc = 0\n",
    "prec = 0\n",
    "rec = 0\n",
    "for train_index, test_index in kf.split(X_use, y_use):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_use.iloc[train_index], X_use.iloc[test_index]\n",
    "    y_train, y_test = y_use[train_index], y_use[test_index]\n",
    "\n",
    "    ro,re,p = train_and_predict(X_train, y_train, X_test, y_test)\n",
    "    roc += ro\n",
    "    prec += p\n",
    "    rec += re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901702894984304"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714769984127279"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8263386396526773"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\balat\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(penalty='l1', solver='liblinear').fit(X_use, y_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = log.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score = roc_auc_score(y_holdout, preds)\n",
    "recall = recall_score(y_holdout, preds)\n",
    "precision = precision_score(y_holdout, preds)\n",
    "r2 = r2_score(y_holdout,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9049479166666667\n",
      "0.8359375\n",
      "0.9697885196374623\n",
      "0.6197916666666667\n"
     ]
    }
   ],
   "source": [
    "print(roc_score)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def logit_pvalue(model, x):\n",
    "    \"\"\" Calculate z-scores for scikit-learn LogisticRegression.\n",
    "    parameters:\n",
    "        model: fitted sklearn.linear_model.LogisticRegression with intercept and large C\n",
    "        x:     matrix on which the model was fit\n",
    "    This function uses asymtptics for maximum likelihood estimates.\n",
    "    \"\"\"\n",
    "    p = model.predict_proba(x)\n",
    "    n = len(p)\n",
    "    m = len(model.coef_[0]) + 1\n",
    "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
    "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
    "    ans = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
    "    vcov = np.linalg.inv(np.matrix(ans))\n",
    "    se = np.sqrt(np.diag(vcov))\n",
    "    t =  coefs/se  \n",
    "    p = (1 - norm.cdf(abs(t))) * 2\n",
    "    return p\n",
    "\n",
    "pvalues = logit_pvalue(log, X_holdout.astype(float))[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = log.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalCRMActivityVolume</td>\n",
       "      <td>0.0946845</td>\n",
       "      <td>0.0128065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Click Email</td>\n",
       "      <td>0.430945</td>\n",
       "      <td>0.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contest</td>\n",
       "      <td>0.65518</td>\n",
       "      <td>0.0902073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fill Out Form</td>\n",
       "      <td>1.85893</td>\n",
       "      <td>0.00501491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Livestream Gate</td>\n",
       "      <td>0.706256</td>\n",
       "      <td>0.120049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Open Email</td>\n",
       "      <td>0.21728</td>\n",
       "      <td>0.0114125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ticket Inquiry Form</td>\n",
       "      <td>0.164975</td>\n",
       "      <td>0.452165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>primary_purchase_transactions</td>\n",
       "      <td>2.61604</td>\n",
       "      <td>8.68623e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0          1            2\n",
       "0         TotalCRMActivityVolume  0.0946845    0.0128065\n",
       "1                    Click Email   0.430945     0.154329\n",
       "2                        Contest    0.65518    0.0902073\n",
       "3                  Fill Out Form    1.85893   0.00501491\n",
       "4                Livestream Gate   0.706256     0.120049\n",
       "5                     Open Email    0.21728    0.0114125\n",
       "6            Ticket Inquiry Form   0.164975     0.452165\n",
       "7  primary_purchase_transactions    2.61604  8.68623e-09"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([X.columns.values, coefs, pvalues]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
